\begin{description}
		\item[\textbf{Web scraping}] -- это сбор данных с различных интернет-ресурсов. Общий принцип его работы можно объяснить следующим образом: некий автоматизированный код выполняет GET-запросы на целевой сайт и получая ответ, парсит HTML-документ, ищет данные и преобразует их в заданный формат. \label{terms:webscraping}
		\item[\textbf{Проект}] -- сущность для объединения и предоставления доступа к запускам/краулерам/периодическим задачам. \label{terms:project}
		
		\item[\textbf{Веб краулер}] --  программа, являющаяся составной частью поисковой системы и предназначенная для перебора страниц Интернета с целью занесения информации о них в базу данных поисковика. Неотъемлемая часть проекта. Именно с помощью пауков пользователь может “краулить” сайты для сбора необходимой информации. \label{terms:spider}
		\item[\textbf{Запуск}] -- единоразовый запуск краулера с настройками и аргументами, указанными для этого запуска. \label{terms:job}
		\item[\textbf{Периодический запуск}] -- запуск с множеством настроек, повторяющийся в определенные периоды времени (запуски по cron-expression).
		\label{terms:pjob}
	\end{description}